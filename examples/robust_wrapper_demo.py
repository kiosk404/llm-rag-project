#!/usr/bin/env python3
"""
é€šç”¨æ¨¡å‹åŒ…è£…å™¨æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ RobustLLMWrapper åŒ…è£…ä¸åŒçš„æ¨¡å‹æä¾›è€…
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.models.wrappers import RobustLLMWrapper, create_robust_wrapper
from app.models.factory import LLMFactory
from langchain_core.language_models import BaseLLM


def demo_basic_wrapper():
    """æ¼”ç¤ºåŸºç¡€åŒ…è£…å™¨ä½¿ç”¨"""
    print("=" * 50)
    print("æ¼”ç¤º1ï¼šåŸºç¡€åŒ…è£…å™¨ä½¿ç”¨")
    print("=" * 50)
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„LLMå®ä¾‹ï¼ˆè¿™é‡Œç”¨å­—ç¬¦ä¸²æ¨¡æ‹Ÿï¼‰
    class MockLLM(BaseLLM):
        def _llm_type(self) -> str:
            return "mock"
        
        def _call(self, prompt: str, **kwargs) -> str:
            # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
            if "error" in prompt.lower():
                raise Exception("æ¨¡æ‹Ÿç½‘ç»œè¿æ¥é”™è¯¯")
            return f"MockLLMå›å¤: {prompt}"
        def _generate(self, prompts, stop=None, run_manager=None, **kwargs):
            # ç®€å•å®ç°ï¼Œè¿”å›æ¯ä¸ªpromptçš„_mockå›å¤
            return type('LLMResult', (), {"generations": [[{"text": self._call(p)}] for p in prompts]})()
    
    # ä½¿ç”¨åŒ…è£…å™¨åŒ…è£…
    mock_llm = MockLLM()
    robust_llm = create_robust_wrapper(
        llm_instance=mock_llm,
        provider_name="Mockæ¨¡å‹",
        max_retries=2,
        retry_delay=1
    )
    
    print("âœ… åŒ…è£…å™¨åˆ›å»ºæˆåŠŸ")
    print(f"æ¨¡å‹ç±»å‹: {robust_llm._llm_type()}")
    
    # æµ‹è¯•æ­£å¸¸è°ƒç”¨
    try:
        result = robust_llm.invoke("ä½ å¥½")
        print(f"æ­£å¸¸è°ƒç”¨ç»“æœ: {result}")
    except Exception as e:
        print(f"è°ƒç”¨å¤±è´¥: {e}")
    
    print()


def demo_custom_error_patterns():
    """æ¼”ç¤ºè‡ªå®šä¹‰é”™è¯¯æ¨¡å¼"""
    print("=" * 50)
    print("æ¼”ç¤º2ï¼šè‡ªå®šä¹‰é”™è¯¯æ¨¡å¼")
    print("=" * 50)
    
    class MockLLM(BaseLLM):
        def _llm_type(self) -> str:
            return "mock"
        
        def _call(self, prompt: str, **kwargs) -> str:
            if "quota" in prompt.lower():
                raise Exception("è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼")
            elif "auth" in prompt.lower():
                raise Exception("APIå¯†é’¥æ— æ•ˆ")
            elif "network" in prompt.lower():
                raise Exception("ç½‘ç»œè¿æ¥è¶…æ—¶")
            return f"MockLLMå›å¤: {prompt}"
        def _generate(self, prompts, stop=None, run_manager=None, **kwargs):
            return type('LLMResult', (), {"generations": [[{"text": self._call(p)}] for p in prompts]})()
    
    # è‡ªå®šä¹‰é”™è¯¯æ¨¡å¼
    custom_patterns = {
        "quota_error": {
            "keywords": ["ä½™é¢ä¸è¶³", "quota", "balance"],
            "message": "è‡ªå®šä¹‰é”™è¯¯ï¼šè´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·åŠæ—¶å……å€¼ã€‚",
            "retry": False
        },
        "auth_error": {
            "keywords": ["å¯†é’¥æ— æ•ˆ", "auth", "unauthorized"],
            "message": "è‡ªå®šä¹‰é”™è¯¯ï¼šAPIå¯†é’¥éªŒè¯å¤±è´¥ã€‚",
            "retry": False
        },
        "network_error": {
            "keywords": ["ç½‘ç»œ", "timeout", "connection"],
            "message": "è‡ªå®šä¹‰é”™è¯¯ï¼šç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ­£åœ¨é‡è¯•...",
            "retry": True
        }
    }
    
    mock_llm = MockLLM()
    robust_llm = create_robust_wrapper(
        llm_instance=mock_llm,
        provider_name="è‡ªå®šä¹‰æ¨¡å‹",
        max_retries=2,
        retry_delay=1,
        custom_error_patterns=custom_patterns
    )
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯
    test_cases = [
        "æ­£å¸¸é—®é¢˜",
        "quotaæµ‹è¯•",
        "authæµ‹è¯•", 
        "networkæµ‹è¯•"
    ]
    
    for test_case in test_cases:
        try:
            result = robust_llm.invoke(test_case)
            print(f"âœ… {test_case}: {result}")
        except Exception as e:
            print(f"âŒ {test_case}: {e}")
    
    print()


def demo_real_providers():
    """æ¼”ç¤ºçœŸå®æ¨¡å‹æä¾›è€…"""
    print("=" * 50)
    print("æ¼”ç¤º3ï¼šçœŸå®æ¨¡å‹æä¾›è€…")
    print("=" * 50)
    
    available_providers = LLMFactory.get_available_providers()
    print(f"å¯ç”¨çš„æ¨¡å‹æä¾›è€…: {available_providers}")
    
    # æµ‹è¯•é€šä¹‰åƒé—®æä¾›è€…ï¼ˆå¦‚æœé…ç½®äº†APIå¯†é’¥ï¼‰
    if "tongyi" in available_providers:
        try:
            provider = LLMFactory.create_provider("tongyi")
            llm = provider.create_llm()
            print(f"âœ… é€šä¹‰åƒé—®æ¨¡å‹åˆ›å»ºæˆåŠŸ: {llm._llm_type()}")
            
            # æµ‹è¯•è¿æ¥ï¼ˆå¦‚æœAPIå¯†é’¥æœ‰æ•ˆï¼‰
            if provider.test_connection():
                print("âœ… é€šä¹‰åƒé—®APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                print("âš ï¸ é€šä¹‰åƒé—®APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼ˆå¯èƒ½æ˜¯APIå¯†é’¥é—®é¢˜ï¼‰")
                
        except Exception as e:
            print(f"âŒ é€šä¹‰åƒé—®æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
    
    # æµ‹è¯•è±†åŒ…æä¾›è€…ï¼ˆå¦‚æœé…ç½®äº†APIå¯†é’¥ï¼‰
    if "doubao" in available_providers:
        try:
            provider = LLMFactory.create_provider("doubao")
            llm = provider.create_llm()
            print(f"âœ… è±†åŒ…æ¨¡å‹åˆ›å»ºæˆåŠŸ: {llm._llm_type()}")
            
            # æµ‹è¯•è¿æ¥ï¼ˆå¦‚æœAPIå¯†é’¥æœ‰æ•ˆï¼‰
            if provider.test_connection():
                print("âœ… è±†åŒ…APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                print("âš ï¸ è±†åŒ…APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼ˆå¯èƒ½æ˜¯APIå¯†é’¥é—®é¢˜ï¼‰")
                
        except Exception as e:
            print(f"âŒ è±†åŒ…æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
    
    print()


def demo_wrapper_features():
    """æ¼”ç¤ºåŒ…è£…å™¨ç‰¹æ€§"""
    print("=" * 50)
    print("æ¼”ç¤º4ï¼šåŒ…è£…å™¨ç‰¹æ€§")
    print("=" * 50)
    
    class MockLLM(BaseLLM):
        def _llm_type(self) -> str:
            return "mock"
        
        def _call(self, prompt: str, **kwargs) -> str:
            return f"MockLLMå›å¤: {prompt}"
        def _generate(self, prompts, stop=None, run_manager=None, **kwargs):
            return type('LLMResult', (), {"generations": [[{"text": self._call(p)}] for p in prompts]})()
    
    mock_llm = MockLLM()
    robust_llm = create_robust_wrapper(
        llm_instance=mock_llm,
        provider_name="ç‰¹æ€§æ¼”ç¤ºæ¨¡å‹",
        max_retries=3,
        retry_delay=1
    )
    
    print("åŒ…è£…å™¨ç‰¹æ€§:")
    print(f"â€¢ æœ€å¤§é‡è¯•æ¬¡æ•°: {robust_llm._max_retries}")
    print(f"â€¢ é‡è¯•å»¶è¿Ÿ: {robust_llm._retry_delay}ç§’")
    print(f"â€¢ æä¾›è€…åç§°: {robust_llm._provider_name}")
    print(f"â€¢ æ¨¡å‹ç±»å‹: {robust_llm._llm_type()}")
    
    # æ¼”ç¤ºåŠ¨æ€æ·»åŠ é”™è¯¯æ¨¡å¼
    robust_llm.add_error_pattern(
        error_type="custom_error",
        keywords=["è‡ªå®šä¹‰", "custom"],
        message="è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰é”™è¯¯æ¨¡å¼",
        retry=True
    )
    
    print("â€¢ æ”¯æŒåŠ¨æ€æ·»åŠ é”™è¯¯æ¨¡å¼")
    print()


if __name__ == "__main__":
    print("ğŸš€ é€šç”¨æ¨¡å‹åŒ…è£…å™¨æ¼”ç¤º")
    print()
    
    demo_basic_wrapper()
    demo_custom_error_patterns()
    demo_real_providers()
    demo_wrapper_features()
    
    print("=" * 50)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 50)
    print()
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. é€šç”¨åŒ…è£…å™¨å¯ä»¥åŒ…è£…ä»»ä½•ç»§æ‰¿è‡ªBaseLLMçš„æ¨¡å‹")
    print("2. æ”¯æŒè‡ªå®šä¹‰é”™è¯¯æ¨¡å¼å’Œé‡è¯•ç­–ç•¥")
    print("3. å¯ä»¥è½»æ¾æ‰©å±•æ”¯æŒæ–°çš„æ¨¡å‹æä¾›è€…")
    print("4. æä¾›äº†ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶") 